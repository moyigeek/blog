---
title: 网安实践5.2
date: 2024-11-15 10:37:25
tags:
---

## IP 地址国别信息查询系统设计

本实验旨在探讨如何使用xdb文件格式（本项目中设计的一种高效且可自定
义的数据格式，用于存储和查询 IP 地址相关信息）在海量数据集下实现高效的
ip 国别信息查询。实验重点包括理解xdb的数据结构与查询流程，结合 IPv4和
IPv6 的实现代码进行分析。同时，实验将使用pyshark捕获实时网络流量并查询
IP 的国别信息，进一步验证查询的实用性和性能。
### 完成过程
1. 理解xdb数据结构
2. 理解xdb的查询流程
3. 编译并运行 IPv4 和 IPv6 查询代码，测试不同数据量下的查询时间
4. 使用pyshark 捕获实时流量，查询ip国别信息


### 基础知识

**xdb数据结构**

|Header 数据段| Vector 索引数据段 |地域信息数据段 | 二分索引数据段|

|256 Bytes| 512 KiB | 动态空间 | 动态空间|

**Header 256 bytes 段**
| 版本号  | 缓存策略 | 文件生成时间 | 索引起始地址 | 索引结束地址 |
|---------|----------|--------------|--------------|--------------|
| 2 Bytes | 2 Bytes  | 4 Bytes      | 4 Bytes      | 4 Bytes      |

主要用于存储xdb文件的元数据。
前 16 字节已被使用，剩余字节保留扩展空间（如存储 MD5 哈希值用于数据完
整性校验）。

**Vector 索引段（512KB**
采用 256x256 的二维数组，根据IP的前两个字节划分。

此部分通过减少二分搜索的范围，大大提高了查询速度，缩小了后续二分查找的
扫描范围。开始位置指向区域二分索引的开始位置，结束位置指向区域二级索引
的结束位置，也就是 vector 索引将整个二分索引分成了 256 × 256 个分区，
便于更快的减少二分索引的查找范围，从而加速查询。每个单元格的空间是固定
的，所以整个 vector 索引段占据的空间为：256 × 256 × 8=524288Bytes=
 512 KiB，这个空间是固定的与原始的 IP 数据行数无关。

**地域信息段:**
存储与每个 IP 段相关的地理信息，编码格式为 UTF-8。
每种唯一的地理信息只需存储一次，避免数据冗余。详细见图2.1。

**二分索引段:**
包含每个 IP 段的起始 IP、结束 IP、数据长度和数据指针。
每个索引项占用 14 个字节，总空间与 IP 段数成正比。

ipv4每个二分索引项占据 14 个字节，详细字段和空间分布如下：

| 开始ip  | 结束ip  | 地域信息数据长度 | 地域信息指针 |
|---------|---------|------------------|--------------|
| 4 Bytes | 4 Bytes | 2 Bytes          | 4 Bytes      |

· IPv4 与 IPv6 存储格式差异及优化设计：
4 Bytes
 IPv6 的数据设计与 IPv4 类似，但由于 IPv6 地址长度为 128 位，因此在
存储和查找方式上做了进一步的优化。首先，IPv6 摒弃了 IPv4 中的二级索引
结构，转而直接使用二分查找来定位地址信息（见表 2.7）。这种调整结合优化
后的数据结构，使得系统可以实现对 IPv6 地址的快速定位，达到了 1 微秒级
的查询效率。
为什么在存储时仅保存 IPv6 地址的前 64 位，而不是像 IPv4 那样存储完
整的起始和结束 IP 段？这是基于 IPv6 地址结构的特点而设计的。IPv6 的
128 位地址分为两个 64 位段：高 64 位用于路由，低 64 位用于标识具体节点。
因此，我们只需存储高 64 位地址和前缀长度，就可以精确确定 IPv6 地址段的
范围。

**xdb查询流程**
{%  asset_img xdb查询流程.png xdb查询流程  %}
1. 读取 Header 数据段，获取索引起始地址和结束地址。
2. 读取 Vector 索引段，根据 IP 的前两个字节定位到对应的区域。
3. 读取二分索引段，根据 IP 的具体值进行二分查找，定位到对应的地域信息。
4. 读取地域信息段，获取地域信息。

### 实验结果

1. 编译并运行 IPv4 和 IPv6 查询代码，测试不同数据量下的查询时间
```
make
chmod +x ip2region
./ip2region -test
```

{% asset_img ip2region.png ip2region %}

2. 使用pyshark 捕获实时流量，查询ip国别信息
```
sudo pip install pyshark 
sudo python3 main.py
```

{% asset_img pyshark.png pyshark %}

### 任务
1. IPv6 查询中哈希映射算法的适用性分析
在 IPv6 查询已经使用二分查找算法的情况下，是否可以通过哈希映射算法
替代二分查找来提高查询效率？请从多个角度进行分析，尝试实现该算法，并与
二分查找算法的执行效果进行对比分析，评估其性能差异。你可以根据自己的实
现过程或分析结果给出最终结论。如果你认为有更高效的实现方法，欢迎附上你
的代码并分享思考过程。
在此部分，提供了 IPv6 二分索引项结构的示例，详细代码逻辑见 2.2.2 节。
查询 IP:2408:8226:a500:43d0:1077:8a4b:a1d0:7790
查询结果: 中国

2. Python 与 C++ 程序通信方案优化
在当前程序中，使用了 Socket 连接来解决 Python 和 C++ 之间的通信问题。
由于 C++ 的高效性，它能够在一秒钟内解析 1,000,000 个 IP 地址，并在高流
量情况下保持稳定和可靠的输出。然而，使用 Socket 进行通信并不是最优的方
案。请写出一种更加高效的解决方案，并附加操作过程。
可使用的参考思路：一种更高效的方案是使用 Python 的 FFI（外部函数接口），
直接在 Python 中调用 C++ 的类和方法，从而避免通过 Socket 进行通信，并
且不需要多次加载数据库。这种方式能够显著提升性能。以下是实现方案：
将 C++ 库编译成共享库（.so 文件），使 Python 能够直接调用。
使用 Python 的 ctypes 或 cffi 库加载这个共享库，并在 Python 中调用 C++
类的方法

修改main.cc,将C++代码封装为C接口，供Python调用
```cpp
extern "C" {
    IP2Region* IP2Region_new(const char* ipv4db, const char* ipv6db) {
        std::string ipv4db_str(ipv4db);
        std::string ipv6db_str(ipv6db);
        return new IP2Region(ipv4db_str, ipv6db_str);
    }

    const char* IP2Region_search(IP2Region* ip2region, const char* ipStr) {
        static std::string result;
        try {
            result = ip2region->search(std::string(ipStr));
        } catch (const std::exception& e) {
            std::cerr << "Error: " << e.what() << std::endl;
            return nullptr;
        }
        return result.c_str();
    }

    void IP2Region_free(IP2Region* ip2region) {
        delete ip2region;
    }
    
}
```
python使用cffi库调用C++代码,先定义C++类的Python封装，然后调用C++代码
```python
ffi = cffi.FFI()
ffi.cdef("""
    typedef struct IP2Region IP2Region;
    IP2Region* IP2Region_new(const char* ipv4db, const char* ipv6db);
    const char* IP2Region_search(IP2Region* ip2region, const char* ipStr);
    void IP2Region_free(IP2Region* ip2region);
""")

ip2region_lib = ffi.dlopen(lib_path)

# 定义C++类的Python封装
class Ip2Region:
    def __init__(self):
        self.obj = ip2region_lib.IP2Region_new(ipv4_xdb.encode('utf-8'), ipv6_xdb.encode('utf-8'))
        if not self.obj:
            raise Exception('init ip2region failed')
        
    def search(self, ip):
        result = ip2region_lib.IP2Region_search(self.obj, ip.encode('utf-8'))
        if result == ffi.NULL:
            raise Exception('search ip failed')
        return ffi.string(result).decode('utf-8')
    
    def __del__(self):
        ip2region_lib.IP2Region_free(self.obj)
```

{%  asset_img cffi.png cffi %}


## 实时分析流量的CDN
了解CDN的作用功能，如何查询CDN，如何确定主流境外服务提供商的
CDN地址范围，如谷歌（重点）、推特、脸书、github等，实时检测分析流量
的使用CDN服务的情况。

CDN（Content Delivery Network，内容分发网络）是一种分布式服务器网
络，其目的是通过将内容分发到更接近用户的服务器节点来加速网站和应用程序
的加载速度，提高访问性能，并降低服务器负载。

### 查询CDN
任务：查询下列网站的CDN


| 网站              | CDN服务提供商                |
|-------------------|------------------------------|
| www.geekflare.com | Cloudflare、BunnyCDN、Fastly |
| www.github.com    | Fastly                       |
| www.youtube.com   | Google                       |
| www.bilibili.com  | ChinaNetCenter/Wangsu        |
| www.facebook.com  | Facebook                     |
| www.taobao.com    | Alibaba                      |
| www.zhihu.com     | Tencent Cloud                |
| www.qq.com        | Tencent Cloud Akamai         |
| www.yahoo.com     | Amazon CloudFront YAHOO      |


1. 使用在线工具查询CDN（推荐）
例如，CDNFinder可以提供整个网站或者特定域名使用的CDN服务。
2. 使用命令行工具查询CDN
首先需要找出域名的IP地址，使用DNSrecordlookup或者DNSWatch找到
对应的IP地址，下面使用在线工具找到IP所有者，可以使用whois等工具

### 获取官方网站的IP地址范围
大型网站会定期发布它的所有IP地址，对此我们可以定期爬取更新，缓存
在我们本地。
任务：仿照附件findIP.py文件编写脚本爬取以下官方网站的IP地址文件
(1)Cloudflare
```python
def get_cloudflare_ips():
    url = "https://www.cloudflare.com/ips-v4"
    response = requests.get(url)
    ip_list = response.text.split("\n")

    with open("cloudflare_ips.txt", "w") as file:
        file.write(f"Total IPs: {len(ip_list)}\n")
        file.write("\n".join(ip_list))
    print("Cloudflare IP addresses have been written to cloudflare_ips.txt")
```
 (2)Amazonaws
```python
def get_aws_ips():
    url = "https://ip-ranges.amazonaws.com/ip-ranges.json"
    response = requests.get(url)
    data = response.json()

    ip_list = []
    max_num = 100 #太多了，只取前100个，虚拟机跑太慢
    for prefix in data["prefixes"]:
        if "ip_prefix" in prefix:
            network = ipaddress.IPv4Network(prefix["ip_prefix"])
            ip_list.extend(str(ip) for ip in network)
            max_num -= 1
            if max_num == 0:
                break

    with open("aws_ips.txt", "w") as file:
        file.write(f"Total IPs: {len(ip_list)}\n")
        file.write("\n".join(ip_list))
    print("AWS IP addresses have been written to aws_ips.txt")
```
### 实时流量分析
在本实验中，我们是用pyshark库进行抓取我们网口动态的流量，对其进- 12
行包的抓取与分析。
任务：尝试运行Capture_demo.py文件，得到实时流量抓取DNS请求结果。

{% asset_img catDns.png cat %}

### 任务
我们最终的目的是实现实时抓取流量，并且解析到使用CDN的情况，所以
需要构建一个常用的CDN_PROVIDER的列表进行对比，所以构建出这个列表十
分关键。
任务：根据上面得到的DNS解析结果（可以将域名或者主机名输出保存为文本
文件），结合CDN查询工具，编写自动化查询CDN的代码，查询10个及以上
的解析到的主机名对应CDN服务提供商并生成列表(避免无效)。
例如：huadong.taobao.com, Alibaba
 g.alicdn.com, Alibaba
（附代码及生成列表）